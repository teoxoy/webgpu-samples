(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[220],{5671:function(e,n,t){"use strict";t.d(n,{T:function(){return c}});var r=t(5893),a=t(9008),i=t.n(a),o=t(1163),s=t(7294),u=t(9147),f=t.n(u);t(2684),t(7319);let l=e=>{let n=(0,s.useRef)(null),a=(0,s.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:a}=e;return{name:n,...function(e){let n;let a=null;{a=document.createElement("div");let i=t(4631);n=i(a,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!0})}return{Container:function(t){return(0,r.jsx)("div",{...t,children:(0,r.jsx)("div",{ref(t){a&&t&&(t.appendChild(a),n.setOption("value",e))}})})}}}(a)}}),e.sources),u=(0,s.useRef)(null),l=(0,s.useMemo)(()=>{if(e.gui){let n=t(4376);return new n.GUI({autoPlace:!1})}},[]),c=(0,o.useRouter)(),d=c.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[g,m]=(0,s.useState)(null),[p,h]=(0,s.useState)(null);return(0,s.useEffect)(()=>{d?h(d[1]):h(a[0].name),l&&u.current&&u.current.appendChild(l.domElement);let t={active:!0},r=()=>{t.active=!1};try{let i=n.current,o=e.init({canvas:i,pageState:t,gui:l});o instanceof Promise&&o.catch(e=>{console.error(e),m(e)})}catch(s){console.error(s),m(s)}return r},[]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(i(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/".concat("teoxoy/webgpu-samples","/tree/main/").concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),g?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Is WebGPU Enabled?"}),(0,r.jsx)("p",{children:"".concat(g)})]}):null]}),(0,r.jsxs)("div",{className:f().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:u}),(0,r.jsx)("canvas",{ref:n})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:f().sourceFileNav,children:(0,r.jsx)("ul",{children:a.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":p==e.name,onClick(){h(e.name)},children:e.name})},n))})}),a.map((e,n)=>(0,r.jsx)(e.Container,{className:f().sourceFileContainer,"data-active":p==e.name},n))]})]})},c=e=>(0,r.jsx)(l,{...e})},2684:function(){if("end"in GPURenderPassEncoder.prototype||(GPURenderPassEncoder.prototype.end=GPURenderPassEncoder.prototype.endPass),"end"in GPUComputePassEncoder.prototype||(GPUComputePassEncoder.prototype.end=GPUComputePassEncoder.prototype.endPass),navigator.userAgent.indexOf("Firefox")>0){let e={info:{icon:"ℹ️",logFn:console.info},warning:{icon:"⚠️",logFn:console.warn},error:{icon:"⛔",logFn:console.error}},n=GPUDevice.prototype.createShaderModule;function t(e){let n=GPUDevice.prototype[e];GPUDevice.prototype[e]=function(e){return"auto"==e.layout&&delete e.layout,n.call(this,e)}}GPUDevice.prototype.createShaderModule=function(t){t.code=t.code.replaceAll("vec4f","vec4<f32>").replaceAll("vec3f","vec3<f32>").replaceAll("vec2f","vec2<f32>").replaceAll("vec4u","vec4<u32>").replaceAll("vec3u","vec3<u32>").replaceAll("vec2u","vec2<u32>").replaceAll("mat4x4f","mat4x4<f32>");let r=n.call(this,t);return r.compilationInfo().then(n=>{if(!n.messages.length)return;let t={error:0,warning:0,info:0};for(let a of n.messages)t[a.type]+=1;0==t.error&&validationError&&(t.error=1);let i=r.label,o=(i?'"'.concat(i,'"'):"Shader")+" returned compilation messages:";for(let s in t)t[s]>0&&(o+=" ".concat(t[s]).concat(e[s].icon));for(let u of(0==t.error?console.groupCollapsed(o):console.group(o),n.messages)){let f=u.type;e[f].logFn(u.message)}console.groupEnd()}),r},t("createRenderPipeline"),t("createRenderPipelineAsync"),t("createComputePipeline"),t("createComputePipelineAsync");let r=GPUCommandEncoder.prototype.beginRenderPass;GPUCommandEncoder.prototype.beginRenderPass=function(e){if(e.colorAttachments)for(let n of e.colorAttachments)"clear"==n.loadOp?n.loadValue=n.clearValue||[0,0,0,0]:n.loadValue="load";if(e.depthStencilAttachment){let t=e.depthStencilAttachment;"load"==t.depthLoadOp?t.depthLoadValue="load":t.depthLoadValue=t.depthClearValue||1,t.depthStoreOp||(t.depthStoreOp="discard"),"load"==t.stencilClearValue?t.stencilLoadValue="load":t.stencilLoadValue=t.stencilClearValue||0,t.stencilStoreOp||(t.stencilStoreOp="discard")}return r.call(this,e)};let a=HTMLCanvasElement.prototype.getContext;HTMLCanvasElement.prototype.getContext=function(){for(var e=arguments.length,n=Array(e),t=0;t<e;t++)n[t]=arguments[t];let r=a.apply(this,n);return"webgpu"==n[0]&&(r.canvas=this),r};let i={},o=GPUCanvasContext.prototype.configure;GPUCanvasContext.prototype.configure=function(e){let n=this;i[n]||(i[n]=new MutationObserver(function(t){let r=!1;for(let a of t)("width"==a.attributeName||"height"==a.attributeName)&&(r=!0);r&&o.call(n,e)})),i[n].observe(n.canvas,{attributes:!0}),o.call(n,e)};let s=GPUCanvasContext.prototype.unconfigure;GPUCanvasContext.prototype.unconfigure=function(e){i[this]&&i[this].disconnect(),s.call(this,e)},GPU.prototype.getPreferredCanvasFormat=function(){return"bgra8unorm"}}},3057:function(e,n,t){"use strict";t.d(n,{W:function(){return o}});var r=t(6906),a=t(7160);let i={xy:[0,1],xz:[0,2],yz:[1,2]},o={positions:r.m,triangles:r.g,normals:[],uvs:[]};o.normals=function(e,n){let t=e.map(()=>[0,0,0]);return n.forEach(n=>{let[r,i,o]=n,s=e[r],u=e[i],f=e[o],l=a.$X(a.Ue(),u,s),c=a.$X(a.Ue(),f,s);a.Fv(l,l),a.Fv(c,c);let d=a.kC(a.Ue(),l,c);a.IH(t[r],t[r],d),a.IH(t[i],t[i],d),a.IH(t[o],t[o],d)}),t.forEach(e=>{a.Fv(e,e)}),t}(o.positions,o.triangles),o.uvs=function(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"xy",t=i[n],r=e.map(()=>[0,0]),a=[1/0,1/0],o=[-1/0,-1/0];return e.forEach((e,n)=>{r[n][0]=e[t[0]],r[n][1]=e[t[1]],a[0]=Math.min(e[t[0]],a[0]),a[1]=Math.min(e[t[1]],a[1]),o[0]=Math.max(e[t[0]],o[0]),o[1]=Math.max(e[t[1]],o[1])}),r.forEach(e=>{e[0]=(e[0]-a[0])/(o[0]-a[0]),e[1]=(e[1]-a[1])/(o[1]-a[1])}),r}(o.positions,"xy"),o.triangles.push([o.positions.length,o.positions.length+2,o.positions.length+1],[o.positions.length,o.positions.length+1,o.positions.length+3]),o.positions.push([-100,20,-100],[100,20,100],[-100,20,100],[100,20,-100]),o.normals.push([0,1,0],[0,1,0],[0,1,0],[0,1,0]),o.uvs.push([0,0],[1,1],[0,1],[1,0])},7220:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return B}});var r=t(5671),a=t(7160),i=t(9685);function o(){var e=new i.WT(4);return i.WT!=Float32Array&&(e[0]=0,e[1]=0,e[2]=0,e[3]=0),e}o();var s=t(5975),u=t(3057),f="struct LightData {\n  position : vec4<f32>,\n  color : vec3<f32>,\n  radius : f32,\n}\nstruct LightsBuffer {\n  lights: array<LightData>,\n}\n@group(0) @binding(0) var<storage, read_write> lightsBuffer: LightsBuffer;\n\nstruct Config {\n  numLights : u32,\n}\n@group(0) @binding(1) var<uniform> config: Config;\n\nstruct LightExtent {\n  min : vec4<f32>,\n  max : vec4<f32>,\n}\n@group(0) @binding(2) var<uniform> lightExtent: LightExtent;\n\n@compute @workgroup_size(64, 1, 1)\nfn main(@builtin(global_invocation_id) GlobalInvocationID : vec3<u32>) {\n  var index = GlobalInvocationID.x;\n  if (index >= config.numLights) {\n    return;\n  }\n\n  lightsBuffer.lights[index].position.y = lightsBuffer.lights[index].position.y - 0.5 - 0.003 * (f32(index) - 64.0 * floor(f32(index) / 64.0));\n\n  if (lightsBuffer.lights[index].position.y < lightExtent.min.y) {\n    lightsBuffer.lights[index].position.y = lightExtent.max.y;\n  }\n}\n",l="struct Uniforms {\n  modelMatrix : mat4x4<f32>,\n  normalModelMatrix : mat4x4<f32>,\n}\nstruct Camera {\n  viewProjectionMatrix : mat4x4<f32>,\n}\n@group(0) @binding(0) var<uniform> uniforms : Uniforms;\n@group(0) @binding(1) var<uniform> camera : Camera;\n\nstruct VertexOutput {\n  @builtin(position) Position : vec4<f32>,\n  @location(0) fragPosition: vec3<f32>,  // position in world space\n  @location(1) fragNormal: vec3<f32>,    // normal in world space\n  @location(2) fragUV: vec2<f32>,\n}\n\n@vertex\nfn main(\n  @location(0) position : vec3<f32>,\n  @location(1) normal : vec3<f32>,\n  @location(2) uv : vec2<f32>\n) -> VertexOutput {\n  var output : VertexOutput;\n  output.fragPosition = (uniforms.modelMatrix * vec4(position, 1.0)).xyz;\n  output.Position = camera.viewProjectionMatrix * vec4(output.fragPosition, 1.0);\n  output.fragNormal = normalize((uniforms.normalModelMatrix * vec4(normal, 1.0)).xyz);\n  output.fragUV = uv;\n  return output;\n}\n",c="struct GBufferOutput {\n  @location(0) position : vec4<f32>,\n  @location(1) normal : vec4<f32>,\n\n  // Textures: diffuse color, specular color, smoothness, emissive etc. could go here\n  @location(2) albedo : vec4<f32>,\n}\n\n@fragment\nfn main(\n  @location(0) fragPosition: vec3<f32>,\n  @location(1) fragNormal: vec3<f32>,\n  @location(2) fragUV : vec2<f32>\n) -> GBufferOutput {\n  // faking some kind of checkerboard texture\n  let uv = floor(30.0 * fragUV);\n  let c = 0.2 + 0.5 * ((uv.x + uv.y) - 2.0 * floor((uv.x + uv.y) / 2.0));\n\n  var output : GBufferOutput;\n  output.position = vec4(fragPosition, 1.0);\n  output.normal = vec4(fragNormal, 1.0);\n  output.albedo = vec4(c, c, c, 1.0);\n\n  return output;\n}\n",d="@vertex\nfn main(\n  @builtin(vertex_index) VertexIndex : u32\n) -> @builtin(position) vec4<f32> {\n  var pos = array(\n    vec2(-1.0, -1.0), vec2(1.0, -1.0), vec2(-1.0, 1.0),\n    vec2(-1.0, 1.0), vec2(1.0, -1.0), vec2(1.0, 1.0),\n  );\n\n  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);\n}\n",g="@group(0) @binding(0) var gBufferPosition: texture_2d<f32>;\n@group(0) @binding(1) var gBufferNormal: texture_2d<f32>;\n@group(0) @binding(2) var gBufferAlbedo: texture_2d<f32>;\n\noverride canvasSizeWidth: f32;\noverride canvasSizeHeight: f32;\n\n@fragment\nfn main(\n  @builtin(position) coord : vec4<f32>\n) -> @location(0) vec4<f32> {\n  var result : vec4<f32>;\n  let c = coord.xy / vec2<f32>(canvasSizeWidth, canvasSizeHeight);\n  if (c.x < 0.33333) {\n    result = textureLoad(\n      gBufferPosition,\n      vec2<i32>(floor(coord.xy)),\n      0\n    );\n  } else if (c.x < 0.66667) {\n    result = textureLoad(\n      gBufferNormal,\n      vec2<i32>(floor(coord.xy)),\n      0\n    );\n    result.x = (result.x + 1.0) * 0.5;\n    result.y = (result.y + 1.0) * 0.5;\n    result.z = (result.z + 1.0) * 0.5;\n  } else {\n    result = textureLoad(\n      gBufferAlbedo,\n      vec2<i32>(floor(coord.xy)),\n      0\n    );\n  }\n  return result;\n}\n",m="@group(0) @binding(0) var gBufferPosition: texture_2d<f32>;\n@group(0) @binding(1) var gBufferNormal: texture_2d<f32>;\n@group(0) @binding(2) var gBufferAlbedo: texture_2d<f32>;\n\nstruct LightData {\n  position : vec4<f32>,\n  color : vec3<f32>,\n  radius : f32,\n}\nstruct LightsBuffer {\n  lights: array<LightData>,\n}\n@group(1) @binding(0) var<storage, read> lightsBuffer: LightsBuffer;\n\nstruct Config {\n  numLights : u32,\n}\n@group(1) @binding(1) var<uniform> config: Config;\n\n@fragment\nfn main(\n  @builtin(position) coord : vec4<f32>\n) -> @location(0) vec4<f32> {\n  var result : vec3<f32>;\n\n  let position = textureLoad(\n    gBufferPosition,\n    vec2<i32>(floor(coord.xy)),\n    0\n  ).xyz;\n\n  if (position.z > 10000.0) {\n    discard;\n  }\n\n  let normal = textureLoad(\n    gBufferNormal,\n    vec2<i32>(floor(coord.xy)),\n    0\n  ).xyz;\n\n  let albedo = textureLoad(\n    gBufferAlbedo,\n    vec2<i32>(floor(coord.xy)),\n    0\n  ).rgb;\n\n  for (var i = 0u; i < config.numLights; i++) {\n    let L = lightsBuffer.lights[i].position.xyz - position;\n    let distance = length(L);\n    if (distance > lightsBuffer.lights[i].radius) {\n      continue;\n    }\n    let lambert = max(dot(normal, normalize(L)), 0.0);\n    result += vec3<f32>(\n      lambert * pow(1.0 - distance / lightsBuffer.lights[i].radius, 2.0) * lightsBuffer.lights[i].color * albedo\n    );\n  }\n\n  // some manual ambient\n  result += vec3(0.2);\n\n  return vec4(result, 1.0);\n}\n",p="src/sample/deferredRendering/main.ts";let h=a.al(-50,-30,-50),v=a.al(50,50,50),x=async e=>{let{canvas:n,pageState:t,gui:r}=e,i=await navigator.gpu.requestAdapter(),p=await i.requestDevice();if(!t.active)return;let x=n.getContext("webgpu"),b=window.devicePixelRatio||1;n.width=n.clientWidth*b,n.height=n.clientHeight*b;let B=n.width/n.height,P=navigator.gpu.getPreferredCanvasFormat();x.configure({device:p,format:P,alphaMode:"opaque"});let y=p.createBuffer({size:8*u.W.positions.length*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0});{let w=new Float32Array(y.getMappedRange());for(let E=0;E<u.W.positions.length;++E)w.set(u.W.positions[E],8*E),w.set(u.W.normals[E],8*E+3),w.set(u.W.uvs[E],8*E+6);y.unmap()}let U=3*u.W.triangles.length,M=p.createBuffer({size:U*Uint16Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.INDEX,mappedAtCreation:!0});{let G=new Uint16Array(M.getMappedRange());for(let T=0;T<u.W.triangles.length;++T)G.set(u.W.triangles[T],3*T);M.unmap()}let A=p.createTexture({size:[n.width,n.height,2],usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING,format:"rgba32float"}),S=p.createTexture({size:[n.width,n.height],usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING,format:"bgra8unorm"}),L=[A.createView({dimension:"2d",baseArrayLayer:0,arrayLayerCount:1}),A.createView({dimension:"2d",baseArrayLayer:1,arrayLayerCount:1}),S.createView()],R=[{arrayStride:8*Float32Array.BYTES_PER_ELEMENT,attributes:[{shaderLocation:0,offset:0,format:"float32x3"},{shaderLocation:1,offset:3*Float32Array.BYTES_PER_ELEMENT,format:"float32x3"},{shaderLocation:2,offset:6*Float32Array.BYTES_PER_ELEMENT,format:"float32x2"}]}],C={topology:"triangle-list",cullMode:"back"},V=p.createRenderPipeline({layout:"auto",vertex:{module:p.createShaderModule({code:l}),entryPoint:"main",buffers:R},fragment:{module:p.createShaderModule({code:c}),entryPoint:"main",targets:[{format:"rgba32float"},{format:"rgba32float"},{format:"bgra8unorm"}]},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth24plus"},primitive:C}),D=p.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.FRAGMENT,texture:{sampleType:"unfilterable-float"}},{binding:1,visibility:GPUShaderStage.FRAGMENT,texture:{sampleType:"unfilterable-float"}},{binding:2,visibility:GPUShaderStage.FRAGMENT,texture:{sampleType:"unfilterable-float"}}]}),_=p.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.FRAGMENT|GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:1,visibility:GPUShaderStage.FRAGMENT|GPUShaderStage.COMPUTE,buffer:{type:"uniform"}}]}),N=p.createRenderPipeline({layout:p.createPipelineLayout({bindGroupLayouts:[D]}),vertex:{module:p.createShaderModule({code:d}),entryPoint:"main"},fragment:{module:p.createShaderModule({code:g}),entryPoint:"main",targets:[{format:P}],constants:{canvasSizeWidth:n.width,canvasSizeHeight:n.height}},primitive:C}),O=p.createRenderPipeline({layout:p.createPipelineLayout({bindGroupLayouts:[D,_]}),vertex:{module:p.createShaderModule({code:d}),entryPoint:"main"},fragment:{module:p.createShaderModule({code:m}),entryPoint:"main",targets:[{format:P}]},primitive:C}),F=p.createTexture({size:[n.width,n.height],format:"depth24plus",usage:GPUTextureUsage.RENDER_ATTACHMENT}),I={colorAttachments:[{view:L[0],clearValue:{r:Number.MAX_VALUE,g:Number.MAX_VALUE,b:Number.MAX_VALUE,a:1},loadOp:"clear",storeOp:"store"},{view:L[1],clearValue:{r:0,g:0,b:1,a:1},loadOp:"clear",storeOp:"store"},{view:L[2],clearValue:{r:0,g:0,b:0,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:F.createView(),depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store"}},z={colorAttachments:[{view:void 0,clearValue:{r:0,g:0,b:0,a:1},loadOp:"clear",storeOp:"store"}]},j={mode:"rendering",numLights:128},W=(()=>{let e=p.createBuffer({size:Uint32Array.BYTES_PER_ELEMENT,mappedAtCreation:!0,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST});return new Uint32Array(e.getMappedRange())[0]=j.numLights,e.unmap(),e})();r.add(j,"mode",["rendering","gBuffers view"]),r.add(j,"numLights",1,1024).step(1).onChange(()=>{p.queue.writeBuffer(W,0,new Uint32Array([j.numLights]))});let k=p.createBuffer({size:128,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),q=p.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),Y=p.createBindGroup({layout:V.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:k}},{binding:1,resource:{buffer:q}}]}),H=p.createBindGroup({layout:D,entries:[{binding:0,resource:L[0]},{binding:1,resource:L[1]},{binding:2,resource:L[2]}]}),X=a.Ue();a.lu(X,v,h);let Q=8192*Float32Array.BYTES_PER_ELEMENT,J=p.createBuffer({size:Q,usage:GPUBufferUsage.STORAGE,mappedAtCreation:!0}),$=new Float32Array(J.getMappedRange()),Z=o(),K=0;for(let ee=0;ee<1024;ee++){K=8*ee;for(let en=0;en<3;en++)Z[en]=Math.random()*X[en]+h[en];Z[3]=1,$.set(Z,K),Z[0]=2*Math.random(),Z[1]=2*Math.random(),Z[2]=2*Math.random(),Z[3]=20,$.set(Z,K+4)}J.unmap();let et=p.createBuffer({size:32,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),er=new Float32Array(8);er.set(h,0),er.set(v,4),p.queue.writeBuffer(et,0,er.buffer,er.byteOffset,er.byteLength);let ea=p.createComputePipeline({layout:"auto",compute:{module:p.createShaderModule({code:f}),entryPoint:"main"}}),ei=p.createBindGroup({layout:_,entries:[{binding:0,resource:{buffer:J}},{binding:1,resource:{buffer:W}}]}),eo=p.createBindGroup({layout:ea.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:J}},{binding:1,resource:{buffer:W}},{binding:2,resource:{buffer:et}}]}),es=a.al(0,50,-100),eu=a.al(0,1,0),ef=a.al(0,0,0),el=s.Ue();s.G3(el,2*Math.PI/5,B,1,2e3);let ec=s.Ue();s.zB(ec,es,ef,eu);let ed=s.Ue();s.Jp(ed,el,ec);let eg=s.Ue();s.Iu(eg,eg,a.al(0,-5,0)),s.Iu(eg,eg,a.al(0,-40,0)),p.queue.writeBuffer(q,0,ed.buffer,ed.byteOffset,ed.byteLength),p.queue.writeBuffer(k,0,eg.buffer,eg.byteOffset,eg.byteLength);let em=s.Ue();s.U_(em,eg),s.p4(em,em),p.queue.writeBuffer(k,64,em.buffer,em.byteOffset,em.byteLength),requestAnimationFrame(function e(){if(!t.active)return;let n=function(){let e=a.al(0,50,-100),n=Math.PI*(Date.now()/5e3);a.uD(e,e,ef,n);let t=s.Ue();return s.zB(t,e,ef,eu),s.Jp(ed,el,t),ed}();p.queue.writeBuffer(q,0,n.buffer,n.byteOffset,n.byteLength);let r=p.createCommandEncoder();{let i=r.beginRenderPass(I);i.setPipeline(V),i.setBindGroup(0,Y),i.setVertexBuffer(0,y),i.setIndexBuffer(M,"uint16"),i.drawIndexed(U),i.end()}{let o=r.beginComputePass();o.setPipeline(ea),o.setBindGroup(0,eo),o.dispatchWorkgroups(Math.ceil(16)),o.end()}if("gBuffers view"===j.mode){z.colorAttachments[0].view=x.getCurrentTexture().createView();let u=r.beginRenderPass(z);u.setPipeline(N),u.setBindGroup(0,H),u.draw(6),u.end()}else{z.colorAttachments[0].view=x.getCurrentTexture().createView();let f=r.beginRenderPass(z);f.setPipeline(O),f.setBindGroup(0,H),f.setBindGroup(1,ei),f.draw(6),f.end()}p.queue.submit([r.finish()]),requestAnimationFrame(e)})},b=()=>(0,r.T)({name:"Deferred Rendering",description:"This example shows how to do deferred rendering with webgpu.\n      Render geometry info to multiple targets in the gBuffers in the first pass.\n      In this sample we have 3 gBuffers for positions, normals, and albedo.\n      And then do the lighting in a second pass with per fragment data read from gBuffers so it's independent of scene complexity.\n      We also update light position in a compute shader, where further operations like tile/cluster culling could happen.",gui:!0,init:x,sources:[{name:p.substring(29),contents:"import { makeSample, SampleInit } from '../../components/SampleLayout';\nimport { mat4, vec3, vec4 } from 'gl-matrix';\nimport { mesh } from '../../meshes/stanfordDragon';\n\nimport lightUpdate from './lightUpdate.wgsl';\nimport vertexWriteGBuffers from './vertexWriteGBuffers.wgsl';\nimport fragmentWriteGBuffers from './fragmentWriteGBuffers.wgsl';\nimport vertexTextureQuad from './vertexTextureQuad.wgsl';\nimport fragmentGBuffersDebugView from './fragmentGBuffersDebugView.wgsl';\nimport fragmentDeferredRendering from './fragmentDeferredRendering.wgsl';\n\nconst kMaxNumLights = 1024;\nconst lightExtentMin = vec3.fromValues(-50, -30, -50);\nconst lightExtentMax = vec3.fromValues(50, 50, 50);\n\nconst init: SampleInit = async ({ canvas, pageState, gui }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (!pageState.active) return;\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  canvas.width = canvas.clientWidth * devicePixelRatio;\n  canvas.height = canvas.clientHeight * devicePixelRatio;\n  const aspect = canvas.width / canvas.height;\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n  context.configure({\n    device,\n    format: presentationFormat,\n    alphaMode: 'opaque',\n  });\n\n  // Create the model vertex buffer.\n  const kVertexStride = 8;\n  const vertexBuffer = device.createBuffer({\n    // position: vec3, normal: vec3, uv: vec2\n    size:\n      mesh.positions.length * kVertexStride * Float32Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Float32Array(vertexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.positions.length; ++i) {\n      mapping.set(mesh.positions[i], kVertexStride * i);\n      mapping.set(mesh.normals[i], kVertexStride * i + 3);\n      mapping.set(mesh.uvs[i], kVertexStride * i + 6);\n    }\n    vertexBuffer.unmap();\n  }\n\n  // Create the model index buffer.\n  const indexCount = mesh.triangles.length * 3;\n  const indexBuffer = device.createBuffer({\n    size: indexCount * Uint16Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.INDEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Uint16Array(indexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.triangles.length; ++i) {\n      mapping.set(mesh.triangles[i], 3 * i);\n    }\n    indexBuffer.unmap();\n  }\n\n  // GBuffer texture render targets\n  const gBufferTexture2DFloat = device.createTexture({\n    size: [canvas.width, canvas.height, 2],\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,\n    format: 'rgba32float',\n  });\n  const gBufferTextureAlbedo = device.createTexture({\n    size: [canvas.width, canvas.height],\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,\n    format: 'bgra8unorm',\n  });\n  const gBufferTextureViews = [\n    gBufferTexture2DFloat.createView({\n      dimension: '2d',\n      baseArrayLayer: 0,\n      arrayLayerCount: 1,\n    }),\n    gBufferTexture2DFloat.createView({\n      dimension: '2d',\n      baseArrayLayer: 1,\n      arrayLayerCount: 1,\n    }),\n    gBufferTextureAlbedo.createView(),\n  ];\n\n  const vertexBuffers: Iterable<GPUVertexBufferLayout> = [\n    {\n      arrayStride: Float32Array.BYTES_PER_ELEMENT * 8,\n      attributes: [\n        {\n          // position\n          shaderLocation: 0,\n          offset: 0,\n          format: 'float32x3',\n        },\n        {\n          // normal\n          shaderLocation: 1,\n          offset: Float32Array.BYTES_PER_ELEMENT * 3,\n          format: 'float32x3',\n        },\n        {\n          // uv\n          shaderLocation: 2,\n          offset: Float32Array.BYTES_PER_ELEMENT * 6,\n          format: 'float32x2',\n        },\n      ],\n    },\n  ];\n\n  const primitive: GPUPrimitiveState = {\n    topology: 'triangle-list',\n    cullMode: 'back',\n  };\n\n  const writeGBuffersPipeline = device.createRenderPipeline({\n    layout: 'auto',\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexWriteGBuffers,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: fragmentWriteGBuffers,\n      }),\n      entryPoint: 'main',\n      targets: [\n        // position\n        { format: 'rgba32float' },\n        // normal\n        { format: 'rgba32float' },\n        // albedo\n        { format: 'bgra8unorm' },\n      ],\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth24plus',\n    },\n    primitive,\n  });\n\n  const gBufferTexturesBindGroupLayout = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'unfilterable-float',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'unfilterable-float',\n        },\n      },\n      {\n        binding: 2,\n        visibility: GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'unfilterable-float',\n        },\n      },\n    ],\n  });\n\n  const lightsBufferBindGroupLayout = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE,\n        buffer: {\n          type: 'read-only-storage',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n    ],\n  });\n\n  const gBuffersDebugViewPipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [gBufferTexturesBindGroupLayout],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexTextureQuad,\n      }),\n      entryPoint: 'main',\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: fragmentGBuffersDebugView,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n      constants: {\n        canvasSizeWidth: canvas.width,\n        canvasSizeHeight: canvas.height,\n      },\n    },\n    primitive,\n  });\n\n  const deferredRenderPipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [\n        gBufferTexturesBindGroupLayout,\n        lightsBufferBindGroupLayout,\n      ],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexTextureQuad,\n      }),\n      entryPoint: 'main',\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: fragmentDeferredRendering,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive,\n  });\n\n  const depthTexture = device.createTexture({\n    size: [canvas.width, canvas.height],\n    format: 'depth24plus',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const writeGBufferPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: gBufferTextureViews[0],\n\n        clearValue: {\n          r: Number.MAX_VALUE,\n          g: Number.MAX_VALUE,\n          b: Number.MAX_VALUE,\n          a: 1.0,\n        },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n      {\n        view: gBufferTextureViews[1],\n\n        clearValue: { r: 0.0, g: 0.0, b: 1.0, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n      {\n        view: gBufferTextureViews[2],\n\n        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n    },\n  };\n\n  const textureQuadPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n  };\n\n  const settings = {\n    mode: 'rendering',\n    numLights: 128,\n  };\n  const configUniformBuffer = (() => {\n    const buffer = device.createBuffer({\n      size: Uint32Array.BYTES_PER_ELEMENT,\n      mappedAtCreation: true,\n      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n    });\n    new Uint32Array(buffer.getMappedRange())[0] = settings.numLights;\n    buffer.unmap();\n    return buffer;\n  })();\n\n  gui.add(settings, 'mode', ['rendering', 'gBuffers view']);\n  gui\n    .add(settings, 'numLights', 1, kMaxNumLights)\n    .step(1)\n    .onChange(() => {\n      device.queue.writeBuffer(\n        configUniformBuffer,\n        0,\n        new Uint32Array([settings.numLights])\n      );\n    });\n\n  const modelUniformBuffer = device.createBuffer({\n    size: 4 * 16 * 2, // two 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const cameraUniformBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneUniformBindGroup = device.createBindGroup({\n    layout: writeGBuffersPipeline.getBindGroupLayout(0),\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: modelUniformBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: {\n          buffer: cameraUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const gBufferTexturesBindGroup = device.createBindGroup({\n    layout: gBufferTexturesBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: gBufferTextureViews[0],\n      },\n      {\n        binding: 1,\n        resource: gBufferTextureViews[1],\n      },\n      {\n        binding: 2,\n        resource: gBufferTextureViews[2],\n      },\n    ],\n  });\n\n  // Lights data are uploaded in a storage buffer\n  // which could be updated/culled/etc. with a compute shader\n  const extent = vec3.create();\n  vec3.sub(extent, lightExtentMax, lightExtentMin);\n  const lightDataStride = 8;\n  const bufferSizeInByte =\n    Float32Array.BYTES_PER_ELEMENT * lightDataStride * kMaxNumLights;\n  const lightsBuffer = device.createBuffer({\n    size: bufferSizeInByte,\n    usage: GPUBufferUsage.STORAGE,\n    mappedAtCreation: true,\n  });\n\n  // We randomaly populate lights randomly in a box range\n  // And simply move them along y-axis per frame to show they are\n  // dynamic lightings\n  const lightData = new Float32Array(lightsBuffer.getMappedRange());\n  const tmpVec4 = vec4.create();\n  let offset = 0;\n  for (let i = 0; i < kMaxNumLights; i++) {\n    offset = lightDataStride * i;\n    // position\n    for (let i = 0; i < 3; i++) {\n      tmpVec4[i] = Math.random() * extent[i] + lightExtentMin[i];\n    }\n    tmpVec4[3] = 1;\n    lightData.set(tmpVec4, offset);\n    // color\n    tmpVec4[0] = Math.random() * 2;\n    tmpVec4[1] = Math.random() * 2;\n    tmpVec4[2] = Math.random() * 2;\n    // radius\n    tmpVec4[3] = 20.0;\n    lightData.set(tmpVec4, offset + 4);\n  }\n  lightsBuffer.unmap();\n\n  const lightExtentBuffer = device.createBuffer({\n    size: 4 * 8,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  const lightExtentData = new Float32Array(8);\n  lightExtentData.set(lightExtentMin, 0);\n  lightExtentData.set(lightExtentMax, 4);\n  device.queue.writeBuffer(\n    lightExtentBuffer,\n    0,\n    lightExtentData.buffer,\n    lightExtentData.byteOffset,\n    lightExtentData.byteLength\n  );\n\n  const lightUpdateComputePipeline = device.createComputePipeline({\n    layout: 'auto',\n    compute: {\n      module: device.createShaderModule({\n        code: lightUpdate,\n      }),\n      entryPoint: 'main',\n    },\n  });\n  const lightsBufferBindGroup = device.createBindGroup({\n    layout: lightsBufferBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: lightsBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: {\n          buffer: configUniformBuffer,\n        },\n      },\n    ],\n  });\n  const lightsBufferComputeBindGroup = device.createBindGroup({\n    layout: lightUpdateComputePipeline.getBindGroupLayout(0),\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: lightsBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: {\n          buffer: configUniformBuffer,\n        },\n      },\n      {\n        binding: 2,\n        resource: {\n          buffer: lightExtentBuffer,\n        },\n      },\n    ],\n  });\n  //--------------------\n\n  // Scene matrices\n  const eyePosition = vec3.fromValues(0, 50, -100);\n  const upVector = vec3.fromValues(0, 1, 0);\n  const origin = vec3.fromValues(0, 0, 0);\n\n  const projectionMatrix = mat4.create();\n  mat4.perspective(projectionMatrix, (2 * Math.PI) / 5, aspect, 1, 2000.0);\n\n  const viewMatrix = mat4.create();\n  mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n  const viewProjMatrix = mat4.create();\n  mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n\n  // Move the model so it's centered.\n  const modelMatrix = mat4.create();\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -5, 0));\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -40, 0));\n\n  const cameraMatrixData = viewProjMatrix as Float32Array;\n  device.queue.writeBuffer(\n    cameraUniformBuffer,\n    0,\n    cameraMatrixData.buffer,\n    cameraMatrixData.byteOffset,\n    cameraMatrixData.byteLength\n  );\n  const modelData = modelMatrix as Float32Array;\n  device.queue.writeBuffer(\n    modelUniformBuffer,\n    0,\n    modelData.buffer,\n    modelData.byteOffset,\n    modelData.byteLength\n  );\n  const invertTransposeModelMatrix = mat4.create();\n  mat4.invert(invertTransposeModelMatrix, modelMatrix);\n  mat4.transpose(invertTransposeModelMatrix, invertTransposeModelMatrix);\n  const normalModelData = invertTransposeModelMatrix as Float32Array;\n  device.queue.writeBuffer(\n    modelUniformBuffer,\n    64,\n    normalModelData.buffer,\n    normalModelData.byteOffset,\n    normalModelData.byteLength\n  );\n\n  // Rotates the camera around the origin based on time.\n  function getCameraViewProjMatrix() {\n    const eyePosition = vec3.fromValues(0, 50, -100);\n\n    const rad = Math.PI * (Date.now() / 5000);\n    vec3.rotateY(eyePosition, eyePosition, origin, rad);\n\n    const viewMatrix = mat4.create();\n    mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n    mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n    return viewProjMatrix as Float32Array;\n  }\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!pageState.active) return;\n\n    const cameraViewProj = getCameraViewProjMatrix();\n    device.queue.writeBuffer(\n      cameraUniformBuffer,\n      0,\n      cameraViewProj.buffer,\n      cameraViewProj.byteOffset,\n      cameraViewProj.byteLength\n    );\n\n    const commandEncoder = device.createCommandEncoder();\n    {\n      // Write position, normal, albedo etc. data to gBuffers\n      const gBufferPass = commandEncoder.beginRenderPass(\n        writeGBufferPassDescriptor\n      );\n      gBufferPass.setPipeline(writeGBuffersPipeline);\n      gBufferPass.setBindGroup(0, sceneUniformBindGroup);\n      gBufferPass.setVertexBuffer(0, vertexBuffer);\n      gBufferPass.setIndexBuffer(indexBuffer, 'uint16');\n      gBufferPass.drawIndexed(indexCount);\n      gBufferPass.end();\n    }\n    {\n      // Update lights position\n      const lightPass = commandEncoder.beginComputePass();\n      lightPass.setPipeline(lightUpdateComputePipeline);\n      lightPass.setBindGroup(0, lightsBufferComputeBindGroup);\n      lightPass.dispatchWorkgroups(Math.ceil(kMaxNumLights / 64));\n      lightPass.end();\n    }\n    {\n      if (settings.mode === 'gBuffers view') {\n        // GBuffers debug view\n        // Left: position\n        // Middle: normal\n        // Right: albedo (use uv to mimic a checkerboard texture)\n        textureQuadPassDescriptor.colorAttachments[0].view = context\n          .getCurrentTexture()\n          .createView();\n        const debugViewPass = commandEncoder.beginRenderPass(\n          textureQuadPassDescriptor\n        );\n        debugViewPass.setPipeline(gBuffersDebugViewPipeline);\n        debugViewPass.setBindGroup(0, gBufferTexturesBindGroup);\n        debugViewPass.draw(6);\n        debugViewPass.end();\n      } else {\n        // Deferred rendering\n        textureQuadPassDescriptor.colorAttachments[0].view = context\n          .getCurrentTexture()\n          .createView();\n        const deferredRenderingPass = commandEncoder.beginRenderPass(\n          textureQuadPassDescriptor\n        );\n        deferredRenderingPass.setPipeline(deferredRenderPipeline);\n        deferredRenderingPass.setBindGroup(0, gBufferTexturesBindGroup);\n        deferredRenderingPass.setBindGroup(1, lightsBufferBindGroup);\n        deferredRenderingPass.draw(6);\n        deferredRenderingPass.end();\n      }\n    }\n    device.queue.submit([commandEncoder.finish()]);\n\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst DeferredRendering: () => JSX.Element = () =>\n  makeSample({\n    name: 'Deferred Rendering',\n    description: `This example shows how to do deferred rendering with webgpu.\n      Render geometry info to multiple targets in the gBuffers in the first pass.\n      In this sample we have 3 gBuffers for positions, normals, and albedo.\n      And then do the lighting in a second pass with per fragment data read from gBuffers so it's independent of scene complexity.\n      We also update light position in a compute shader, where further operations like tile/cluster culling could happen.`,\n    gui: true,\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: 'vertexWriteGBuffers.wgsl',\n        contents: vertexWriteGBuffers,\n        editable: true,\n      },\n      {\n        name: 'fragmentWriteGBuffers.wgsl',\n        contents: fragmentWriteGBuffers,\n        editable: true,\n      },\n      {\n        name: 'vertexTextureQuad.wgsl',\n        contents: vertexTextureQuad,\n        editable: true,\n      },\n      {\n        name: 'fragmentGBuffersDebugView.wgsl',\n        contents: fragmentGBuffersDebugView,\n        editable: true,\n      },\n      {\n        name: 'fragmentDeferredRendering.wgsl',\n        contents: fragmentDeferredRendering,\n        editable: true,\n      },\n      {\n        name: 'lightUpdate.wgsl',\n        contents: lightUpdate,\n        editable: true,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default DeferredRendering;\n"},{name:"vertexWriteGBuffers.wgsl",contents:l,editable:!0},{name:"fragmentWriteGBuffers.wgsl",contents:c,editable:!0},{name:"vertexTextureQuad.wgsl",contents:d,editable:!0},{name:"fragmentGBuffersDebugView.wgsl",contents:g,editable:!0},{name:"fragmentDeferredRendering.wgsl",contents:m,editable:!0},{name:"lightUpdate.wgsl",contents:f,editable:!0}],filename:p});var B=b},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x"}}}]);