(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[342],{5671:function(e,n,t){"use strict";t.d(n,{T:function(){return d}});var r=t(5893),a=t(9008),o=t.n(a),i=t(1163),s=t(7294),l=t(9147),c=t.n(l);t(2684),t(7319);let u=e=>{let n=(0,s.useRef)(null),a=(0,s.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:a}=e;return{name:n,...function(e){let n;let a=null;{a=document.createElement("div");let o=t(4631);n=o(a,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!0})}return{Container:function(t){return(0,r.jsx)("div",{...t,children:(0,r.jsx)("div",{ref(t){a&&t&&(t.appendChild(a),n.setOption("value",e))}})})}}}(a)}}),e.sources),l=(0,s.useRef)(null),u=(0,s.useMemo)(()=>{if(e.gui){let n=t(4376);return new n.GUI({autoPlace:!1})}},[]),d=(0,i.useRouter)(),p=d.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[f,m]=(0,s.useState)(null),[h,g]=(0,s.useState)(null);return(0,s.useEffect)(()=>{p?g(p[1]):g(a[0].name),u&&l.current&&l.current.appendChild(u.domElement);let t={active:!0},r=()=>{t.active=!1};try{let o=n.current,i=e.init({canvas:o,pageState:t,gui:u});i instanceof Promise&&i.catch(e=>{console.error(e),m(e)})}catch(s){console.error(s),m(s)}return r},[]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(o(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/".concat("teoxoy/webgpu-samples","/tree/main/").concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),f?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Is WebGPU Enabled?"}),(0,r.jsx)("p",{children:"".concat(f)})]}):null]}),(0,r.jsxs)("div",{className:c().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:l}),(0,r.jsx)("canvas",{ref:n})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:c().sourceFileNav,children:(0,r.jsx)("ul",{children:a.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":h==e.name,onClick(){g(e.name)},children:e.name})},n))})}),a.map((e,n)=>(0,r.jsx)(e.Container,{className:c().sourceFileContainer,"data-active":h==e.name},n))]})]})},d=e=>(0,r.jsx)(u,{...e})},2684:function(){if("end"in GPURenderPassEncoder.prototype||(GPURenderPassEncoder.prototype.end=GPURenderPassEncoder.prototype.endPass),"end"in GPUComputePassEncoder.prototype||(GPUComputePassEncoder.prototype.end=GPUComputePassEncoder.prototype.endPass),navigator.userAgent.indexOf("Firefox")>0){let e={info:{icon:"ℹ️",logFn:console.info},warning:{icon:"⚠️",logFn:console.warn},error:{icon:"⛔",logFn:console.error}},n=GPUDevice.prototype.createShaderModule;function t(e){let n=GPUDevice.prototype[e];GPUDevice.prototype[e]=function(e){return"auto"==e.layout&&delete e.layout,n.call(this,e)}}GPUDevice.prototype.createShaderModule=function(t){t.code=t.code.replaceAll("vec4f","vec4<f32>").replaceAll("vec3f","vec3<f32>").replaceAll("vec2f","vec2<f32>").replaceAll("vec4u","vec4<u32>").replaceAll("vec3u","vec3<u32>").replaceAll("vec2u","vec2<u32>").replaceAll("mat4x4f","mat4x4<f32>");let r=n.call(this,t);return r.compilationInfo().then(n=>{if(!n.messages.length)return;let t={error:0,warning:0,info:0};for(let a of n.messages)t[a.type]+=1;0==t.error&&validationError&&(t.error=1);let o=r.label,i=(o?'"'.concat(o,'"'):"Shader")+" returned compilation messages:";for(let s in t)t[s]>0&&(i+=" ".concat(t[s]).concat(e[s].icon));for(let l of(0==t.error?console.groupCollapsed(i):console.group(i),n.messages)){let c=l.type;e[c].logFn(l.message)}console.groupEnd()}),r},t("createRenderPipeline"),t("createRenderPipelineAsync"),t("createComputePipeline"),t("createComputePipelineAsync");let r=GPUCommandEncoder.prototype.beginRenderPass;GPUCommandEncoder.prototype.beginRenderPass=function(e){if(e.colorAttachments)for(let n of e.colorAttachments)"clear"==n.loadOp?n.loadValue=n.clearValue||[0,0,0,0]:n.loadValue="load";if(e.depthStencilAttachment){let t=e.depthStencilAttachment;"load"==t.depthLoadOp?t.depthLoadValue="load":t.depthLoadValue=t.depthClearValue||1,t.depthStoreOp||(t.depthStoreOp="discard"),"load"==t.stencilClearValue?t.stencilLoadValue="load":t.stencilLoadValue=t.stencilClearValue||0,t.stencilStoreOp||(t.stencilStoreOp="discard")}return r.call(this,e)};let a=HTMLCanvasElement.prototype.getContext;HTMLCanvasElement.prototype.getContext=function(){for(var e=arguments.length,n=Array(e),t=0;t<e;t++)n[t]=arguments[t];let r=a.apply(this,n);return"webgpu"==n[0]&&(r.canvas=this),r};let o={},i=GPUCanvasContext.prototype.configure;GPUCanvasContext.prototype.configure=function(e){let n=this;o[n]||(o[n]=new MutationObserver(function(t){let r=!1;for(let a of t)("width"==a.attributeName||"height"==a.attributeName)&&(r=!0);r&&i.call(n,e)})),o[n].observe(n.canvas,{attributes:!0}),i.call(n,e)};let s=GPUCanvasContext.prototype.unconfigure;GPUCanvasContext.prototype.unconfigure=function(e){o[this]&&o[this].disconnect(),s.call(this,e)},GPU.prototype.getPreferredCanvasFormat=function(){return"bgra8unorm"}}},3057:function(e,n,t){"use strict";t.d(n,{W:function(){return i}});var r=t(6906),a=t(7160);let o={xy:[0,1],xz:[0,2],yz:[1,2]},i={positions:r.m,triangles:r.g,normals:[],uvs:[]};i.normals=function(e,n){let t=e.map(()=>[0,0,0]);return n.forEach(n=>{let[r,o,i]=n,s=e[r],l=e[o],c=e[i],u=a.$X(a.Ue(),l,s),d=a.$X(a.Ue(),c,s);a.Fv(u,u),a.Fv(d,d);let p=a.kC(a.Ue(),u,d);a.IH(t[r],t[r],p),a.IH(t[o],t[o],p),a.IH(t[i],t[i],p)}),t.forEach(e=>{a.Fv(e,e)}),t}(i.positions,i.triangles),i.uvs=function(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"xy",t=o[n],r=e.map(()=>[0,0]),a=[1/0,1/0],i=[-1/0,-1/0];return e.forEach((e,n)=>{r[n][0]=e[t[0]],r[n][1]=e[t[1]],a[0]=Math.min(e[t[0]],a[0]),a[1]=Math.min(e[t[1]],a[1]),i[0]=Math.max(e[t[0]],i[0]),i[1]=Math.max(e[t[1]],i[1])}),r.forEach(e=>{e[0]=(e[0]-a[0])/(i[0]-a[0]),e[1]=(e[1]-a[1])/(i[1]-a[1])}),r}(i.positions,"xy"),i.triangles.push([i.positions.length,i.positions.length+2,i.positions.length+1],[i.positions.length,i.positions.length+1,i.positions.length+3]),i.positions.push([-100,20,-100],[100,20,100],[-100,20,100],[100,20,-100]),i.normals.push([0,1,0],[0,1,0],[0,1,0],[0,1,0]),i.uvs.push([0,0],[1,1],[0,1],[1,0])},2342:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return f}});var r=t(7160),a=t(5975),o=t(5671),i=t(3057),s="struct Scene {\n  lightViewProjMatrix: mat4x4<f32>,\n  cameraViewProjMatrix: mat4x4<f32>,\n  lightPos: vec3<f32>,\n}\n\nstruct Model {\n  modelMatrix: mat4x4<f32>,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(1) @binding(0) var<uniform> model : Model;\n\n@vertex\nfn main(\n  @location(0) position: vec3<f32>\n) -> @builtin(position) vec4<f32> {\n  return scene.lightViewProjMatrix * model.modelMatrix * vec4(position, 1.0);\n}\n",l="struct Scene {\n  lightViewProjMatrix: mat4x4<f32>,\n  cameraViewProjMatrix: mat4x4<f32>,\n  lightPos: vec3<f32>,\n}\n\nstruct Model {\n  modelMatrix: mat4x4<f32>,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(1) @binding(0) var<uniform> model : Model;\n\nstruct VertexOutput {\n  @location(0) shadowPos: vec3<f32>,\n  @location(1) fragPos: vec3<f32>,\n  @location(2) fragNorm: vec3<f32>,\n\n  @builtin(position) Position: vec4<f32>,\n}\n\n@vertex\nfn main(\n  @location(0) position: vec3<f32>,\n  @location(1) normal: vec3<f32>\n) -> VertexOutput {\n  var output : VertexOutput;\n\n  // XY is in (-1, 1) space, Z is in (0, 1) space\n  let posFromLight = scene.lightViewProjMatrix * model.modelMatrix * vec4(position, 1.0);\n\n  // Convert XY to (0, 1)\n  // Y is flipped because texture coords are Y-down.\n  output.shadowPos = vec3(\n    posFromLight.xy * vec2(0.5, -0.5) + vec2(0.5),\n    posFromLight.z\n  );\n\n  output.Position = scene.cameraViewProjMatrix * model.modelMatrix * vec4(position, 1.0);\n  output.fragPos = output.Position.xyz;\n  output.fragNorm = normal;\n  return output;\n}\n",c="const shadowDepthTextureSize: f32 = 1024.0;\n\nstruct Scene {\n  lightViewProjMatrix : mat4x4<f32>,\n  cameraViewProjMatrix : mat4x4<f32>,\n  lightPos : vec3<f32>,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(0) @binding(1) var shadowMap: texture_depth_2d;\n@group(0) @binding(2) var shadowSampler: sampler_comparison;\n\nstruct FragmentInput {\n  @location(0) shadowPos : vec3<f32>,\n  @location(1) fragPos : vec3<f32>,\n  @location(2) fragNorm : vec3<f32>,\n}\n\nconst albedo = vec3<f32>(0.9, 0.9, 0.9);\nconst ambientFactor = 0.2;\n\n@fragment\nfn main(input : FragmentInput) -> @location(0) vec4<f32> {\n  // Percentage-closer filtering. Sample texels in the region\n  // to smooth the result.\n  var visibility = 0.0;\n  let oneOverShadowDepthTextureSize = 1.0 / shadowDepthTextureSize;\n  for (var y = -1; y <= 1; y++) {\n    for (var x = -1; x <= 1; x++) {\n      let offset = vec2<f32>(vec2(x, y)) * oneOverShadowDepthTextureSize;\n\n      visibility += textureSampleCompare(\n        shadowMap, shadowSampler,\n        input.shadowPos.xy + offset, input.shadowPos.z - 0.007\n      );\n    }\n  }\n  visibility /= 9.0;\n\n  let lambertFactor = max(dot(normalize(scene.lightPos - input.fragPos), input.fragNorm), 0.0);\n  let lightingFactor = min(ambientFactor + visibility * lambertFactor, 1.0);\n\n  return vec4(lightingFactor * albedo, 1.0);\n}\n",u="src/sample/shadowMapping/main.ts";let d=async e=>{let{canvas:n,pageState:t}=e,o=await navigator.gpu.requestAdapter(),u=await o.requestDevice();if(!t.active)return;let d=n.getContext("webgpu"),p=window.devicePixelRatio||1;n.width=n.clientWidth*p,n.height=n.clientHeight*p;let f=n.width/n.height,m=navigator.gpu.getPreferredCanvasFormat();d.configure({device:u,format:m,alphaMode:"opaque"});let h=u.createBuffer({size:6*i.W.positions.length*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0});{let g=new Float32Array(h.getMappedRange());for(let v=0;v<i.W.positions.length;++v)g.set(i.W.positions[v],6*v),g.set(i.W.normals[v],6*v+3);h.unmap()}let x=3*i.W.triangles.length,P=u.createBuffer({size:x*Uint16Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.INDEX,mappedAtCreation:!0});{let w=new Uint16Array(P.getMappedRange());for(let y=0;y<i.W.triangles.length;++y)w.set(i.W.triangles[y],3*y);P.unmap()}let b=u.createTexture({size:[1024,1024,1],usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING,format:"depth32float"}),S=b.createView(),M=[{arrayStride:6*Float32Array.BYTES_PER_ELEMENT,attributes:[{shaderLocation:0,offset:0,format:"float32x3"},{shaderLocation:1,offset:3*Float32Array.BYTES_PER_ELEMENT,format:"float32x3"}]}],E={topology:"triangle-list",cullMode:"back"},B=u.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.VERTEX,buffer:{type:"uniform"}}]}),G=u.createRenderPipeline({layout:u.createPipelineLayout({bindGroupLayouts:[B,B]}),vertex:{module:u.createShaderModule({code:s}),entryPoint:"main",buffers:M},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth32float"},primitive:E}),U=u.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,buffer:{type:"uniform"}},{binding:1,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,texture:{sampleType:"depth"}},{binding:2,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,sampler:{type:"comparison"}}]}),T=u.createRenderPipeline({layout:u.createPipelineLayout({bindGroupLayouts:[U,B]}),vertex:{module:u.createShaderModule({code:l}),entryPoint:"main",buffers:M},fragment:{module:u.createShaderModule({code:c}),entryPoint:"main",targets:[{format:m}],constants:{shadowDepthTextureSize:1024}},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth24plus-stencil8"},primitive:E}),C=u.createTexture({size:[n.width,n.height],format:"depth24plus-stencil8",usage:GPUTextureUsage.RENDER_ATTACHMENT}),R={colorAttachments:[{view:void 0,clearValue:{r:.5,g:.5,b:.5,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:C.createView(),depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store",stencilClearValue:0,stencilLoadOp:"clear",stencilStoreOp:"store"}},V=u.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),L=u.createBuffer({size:144,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),A=u.createBindGroup({layout:B,entries:[{binding:0,resource:{buffer:L}}]}),F=u.createBindGroup({layout:U,entries:[{binding:0,resource:{buffer:L}},{binding:1,resource:S},{binding:2,resource:u.createSampler({compare:"less"})}]}),D=u.createBindGroup({layout:B,entries:[{binding:0,resource:{buffer:V}}]}),_=r.al(0,50,-100),j=r.al(0,1,0),O=r.al(0,0,0),N=a.Ue();a.G3(N,2*Math.PI/5,f,1,2e3);let I=a.Ue();a.zB(I,_,O,j);let z=r.al(50,100,-100),W=a.Ue();a.zB(W,z,O,j);let q=a.Ue();a.M5(q,-80,80,-80,80,-200,300);let X=a.Ue();a.Jp(X,q,W);let Y=a.Ue();a.Jp(Y,N,I);let k=a.Ue();a.Iu(k,k,r.al(0,-5,0)),a.Iu(k,k,r.al(0,-40,0)),u.queue.writeBuffer(L,0,X.buffer,X.byteOffset,X.byteLength),u.queue.writeBuffer(L,64,Y.buffer,Y.byteOffset,Y.byteLength),u.queue.writeBuffer(L,128,z.buffer,z.byteOffset,z.byteLength),u.queue.writeBuffer(V,0,k.buffer,k.byteOffset,k.byteLength);let H={colorAttachments:[],depthStencilAttachment:{view:S,depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store"}};requestAnimationFrame(function e(){if(!t.active)return;let n=function(){let e=r.al(0,50,-100),n=Math.PI*(Date.now()/2e3);r.uD(e,e,O,n);let t=a.Ue();return a.zB(t,e,O,j),a.Jp(Y,N,t),Y}();u.queue.writeBuffer(L,64,n.buffer,n.byteOffset,n.byteLength),R.colorAttachments[0].view=d.getCurrentTexture().createView();let o=u.createCommandEncoder();{let i=o.beginRenderPass(H);i.setPipeline(G),i.setBindGroup(0,A),i.setBindGroup(1,D),i.setVertexBuffer(0,h),i.setIndexBuffer(P,"uint16"),i.drawIndexed(x),i.end()}{let s=o.beginRenderPass(R);s.setPipeline(T),s.setBindGroup(0,F),s.setBindGroup(1,D),s.setVertexBuffer(0,h),s.setIndexBuffer(P,"uint16"),s.drawIndexed(x),s.end()}u.queue.submit([o.finish()]),requestAnimationFrame(e)})},p=()=>(0,o.T)({name:"Shadow Mapping",description:"This example shows how to sample from a depth texture to render shadows.",init:d,sources:[{name:u.substring(25),contents:"import { mat4, vec3 } from 'gl-matrix';\nimport { makeSample, SampleInit } from '../../components/SampleLayout';\n\nimport { mesh } from '../../meshes/stanfordDragon';\n\nimport vertexShadowWGSL from './vertexShadow.wgsl';\nimport vertexWGSL from './vertex.wgsl';\nimport fragmentWGSL from './fragment.wgsl';\n\nconst shadowDepthTextureSize = 1024;\n\nconst init: SampleInit = async ({ canvas, pageState }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (!pageState.active) return;\n\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  canvas.width = canvas.clientWidth * devicePixelRatio;\n  canvas.height = canvas.clientHeight * devicePixelRatio;\n  const aspect = canvas.width / canvas.height;\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n  context.configure({\n    device,\n    format: presentationFormat,\n    alphaMode: 'opaque',\n  });\n\n  // Create the model vertex buffer.\n  const vertexBuffer = device.createBuffer({\n    size: mesh.positions.length * 3 * 2 * Float32Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Float32Array(vertexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.positions.length; ++i) {\n      mapping.set(mesh.positions[i], 6 * i);\n      mapping.set(mesh.normals[i], 6 * i + 3);\n    }\n    vertexBuffer.unmap();\n  }\n\n  // Create the model index buffer.\n  const indexCount = mesh.triangles.length * 3;\n  const indexBuffer = device.createBuffer({\n    size: indexCount * Uint16Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.INDEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Uint16Array(indexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.triangles.length; ++i) {\n      mapping.set(mesh.triangles[i], 3 * i);\n    }\n    indexBuffer.unmap();\n  }\n\n  // Create the depth texture for rendering/sampling the shadow map.\n  const shadowDepthTexture = device.createTexture({\n    size: [shadowDepthTextureSize, shadowDepthTextureSize, 1],\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,\n    format: 'depth32float',\n  });\n  const shadowDepthTextureView = shadowDepthTexture.createView();\n\n  // Create some common descriptors used for both the shadow pipeline\n  // and the color rendering pipeline.\n  const vertexBuffers: Iterable<GPUVertexBufferLayout> = [\n    {\n      arrayStride: Float32Array.BYTES_PER_ELEMENT * 6,\n      attributes: [\n        {\n          // position\n          shaderLocation: 0,\n          offset: 0,\n          format: 'float32x3',\n        },\n        {\n          // normal\n          shaderLocation: 1,\n          offset: Float32Array.BYTES_PER_ELEMENT * 3,\n          format: 'float32x3',\n        },\n      ],\n    },\n  ];\n\n  const primitive: GPUPrimitiveState = {\n    topology: 'triangle-list',\n    cullMode: 'back',\n  };\n\n  const uniformBufferBindGroupLayout = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.VERTEX,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n    ],\n  });\n\n  const shadowPipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [\n        uniformBufferBindGroupLayout,\n        uniformBufferBindGroupLayout,\n      ],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexShadowWGSL,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth32float',\n    },\n    primitive,\n  });\n\n  // Create a bind group layout which holds the scene uniforms and\n  // the texture+sampler for depth. We create it manually because the WebPU\n  // implementation doesn't infer this from the shader (yet).\n  const bglForRender = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'depth',\n        },\n      },\n      {\n        binding: 2,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        sampler: {\n          type: 'comparison',\n        },\n      },\n    ],\n  });\n\n  const pipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [bglForRender, uniformBufferBindGroupLayout],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexWGSL,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: fragmentWGSL,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n      constants: {\n        shadowDepthTextureSize,\n      },\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth24plus-stencil8',\n    },\n    primitive,\n  });\n\n  const depthTexture = device.createTexture({\n    size: [canvas.width, canvas.height],\n    format: 'depth24plus-stencil8',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        clearValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n      stencilClearValue: 0,\n      stencilLoadOp: 'clear',\n      stencilStoreOp: 'store',\n    },\n  };\n\n  const modelUniformBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneUniformBuffer = device.createBuffer({\n    // Two 4x4 viewProj matrices,\n    // one for the camera and one for the light.\n    // Then a vec3 for the light position.\n    // Rounded to the nearest multiple of 16.\n    size: 2 * 4 * 16 + 4 * 4,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneBindGroupForShadow = device.createBindGroup({\n    layout: uniformBufferBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const sceneBindGroupForRender = device.createBindGroup({\n    layout: bglForRender,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: shadowDepthTextureView,\n      },\n      {\n        binding: 2,\n        resource: device.createSampler({\n          compare: 'less',\n        }),\n      },\n    ],\n  });\n\n  const modelBindGroup = device.createBindGroup({\n    layout: uniformBufferBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: modelUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const eyePosition = vec3.fromValues(0, 50, -100);\n  const upVector = vec3.fromValues(0, 1, 0);\n  const origin = vec3.fromValues(0, 0, 0);\n\n  const projectionMatrix = mat4.create();\n  mat4.perspective(projectionMatrix, (2 * Math.PI) / 5, aspect, 1, 2000.0);\n\n  const viewMatrix = mat4.create();\n  mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n  const lightPosition = vec3.fromValues(50, 100, -100);\n  const lightViewMatrix = mat4.create();\n  mat4.lookAt(lightViewMatrix, lightPosition, origin, upVector);\n\n  const lightProjectionMatrix = mat4.create();\n  {\n    const left = -80;\n    const right = 80;\n    const bottom = -80;\n    const top = 80;\n    const near = -200;\n    const far = 300;\n    mat4.ortho(lightProjectionMatrix, left, right, bottom, top, near, far);\n  }\n\n  const lightViewProjMatrix = mat4.create();\n  mat4.multiply(lightViewProjMatrix, lightProjectionMatrix, lightViewMatrix);\n\n  const viewProjMatrix = mat4.create();\n  mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n\n  // Move the model so it's centered.\n  const modelMatrix = mat4.create();\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -5, 0));\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -40, 0));\n\n  // The camera/light aren't moving, so write them into buffers now.\n  {\n    const lightMatrixData = lightViewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      0,\n      lightMatrixData.buffer,\n      lightMatrixData.byteOffset,\n      lightMatrixData.byteLength\n    );\n\n    const cameraMatrixData = viewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraMatrixData.buffer,\n      cameraMatrixData.byteOffset,\n      cameraMatrixData.byteLength\n    );\n\n    const lightData = lightPosition as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      128,\n      lightData.buffer,\n      lightData.byteOffset,\n      lightData.byteLength\n    );\n\n    const modelData = modelMatrix as Float32Array;\n    device.queue.writeBuffer(\n      modelUniformBuffer,\n      0,\n      modelData.buffer,\n      modelData.byteOffset,\n      modelData.byteLength\n    );\n  }\n\n  // Rotates the camera around the origin based on time.\n  function getCameraViewProjMatrix() {\n    const eyePosition = vec3.fromValues(0, 50, -100);\n\n    const rad = Math.PI * (Date.now() / 2000);\n    vec3.rotateY(eyePosition, eyePosition, origin, rad);\n\n    const viewMatrix = mat4.create();\n    mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n    mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n    return viewProjMatrix as Float32Array;\n  }\n\n  const shadowPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [],\n    depthStencilAttachment: {\n      view: shadowDepthTextureView,\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n    },\n  };\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!pageState.active) return;\n\n    const cameraViewProj = getCameraViewProjMatrix();\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraViewProj.buffer,\n      cameraViewProj.byteOffset,\n      cameraViewProj.byteLength\n    );\n\n    renderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    {\n      const shadowPass = commandEncoder.beginRenderPass(shadowPassDescriptor);\n      shadowPass.setPipeline(shadowPipeline);\n      shadowPass.setBindGroup(0, sceneBindGroupForShadow);\n      shadowPass.setBindGroup(1, modelBindGroup);\n      shadowPass.setVertexBuffer(0, vertexBuffer);\n      shadowPass.setIndexBuffer(indexBuffer, 'uint16');\n      shadowPass.drawIndexed(indexCount);\n\n      shadowPass.end();\n    }\n    {\n      const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor);\n      renderPass.setPipeline(pipeline);\n      renderPass.setBindGroup(0, sceneBindGroupForRender);\n      renderPass.setBindGroup(1, modelBindGroup);\n      renderPass.setVertexBuffer(0, vertexBuffer);\n      renderPass.setIndexBuffer(indexBuffer, 'uint16');\n      renderPass.drawIndexed(indexCount);\n\n      renderPass.end();\n    }\n    device.queue.submit([commandEncoder.finish()]);\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst ShadowMapping: () => JSX.Element = () =>\n  makeSample({\n    name: 'Shadow Mapping',\n    description:\n      'This example shows how to sample from a depth texture to render shadows.',\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: './vertexShadow.wgsl',\n        contents: vertexShadowWGSL,\n        editable: true,\n      },\n      {\n        name: './vertex.wgsl',\n        contents: vertexWGSL,\n        editable: true,\n      },\n      {\n        name: './fragment.wgsl',\n        contents: fragmentWGSL,\n        editable: true,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default ShadowMapping;\n"},{name:"./vertexShadow.wgsl",contents:s,editable:!0},{name:"./vertex.wgsl",contents:l,editable:!0},{name:"./fragment.wgsl",contents:c,editable:!0}],filename:u});var f=p},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x"}}}]);